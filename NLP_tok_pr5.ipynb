{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Input text\n",
        "text = \"Natural Language Processing helps computers understand human language.\"\n",
        "\n",
        "# a. Tokenization using regex\n",
        "tokens = re.findall(r'\\b\\w+\\b', text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# b. Word Frequency\n",
        "freq = Counter(tokens)\n",
        "print(\"Word Frequency:\", freq)\n",
        "\n",
        "# c. Remove Stop Words (using custom stopword list)\n",
        "stop_words = {\n",
        "    'a', 'an', 'the', 'and', 'or', 'in', 'on', 'of', 'at', 'for', 'to',\n",
        "    'is', 'are', 'was', 'were', 'be', 'been', 'has', 'have', 'had', 'this',\n",
        "    'that', 'it', 'with', 'as', 'by', 'but', 'from', 'he', 'she', 'they',\n",
        "    'them', 'his', 'her', 'their', 'you', 'your', 'we', 'us', 'i', 'me'\n",
        "}\n",
        "\n",
        "filtered = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(\"After Removing Stop Words:\", filtered)\n",
        "\n",
        "# d. Simple POS Tagging (basic simulation using suffix rules)\n",
        "def simple_pos_tag(word):\n",
        "    if word.endswith('ing'):\n",
        "        return (word, 'VBG')  # Verb, gerund\n",
        "    elif word.endswith('ed'):\n",
        "        return (word, 'VBD')  # Verb, past tense\n",
        "    elif word.istitle():\n",
        "        return (word, 'NNP')  # Proper noun\n",
        "    elif word.endswith('s'):\n",
        "        return (word, 'NNS')  # Plural noun\n",
        "    else:\n",
        "        return (word, 'NN')   # Assume noun\n",
        "\n",
        "pos_tags = [simple_pos_tag(word) for word in filtered]\n",
        "print(\"POS Tags:\", pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6eNcto7qs8U",
        "outputId": "f7158cc2-f70f-4a74-d54f-8775021363bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'helps', 'computers', 'understand', 'human', 'language']\n",
            "Word Frequency: Counter({'Natural': 1, 'Language': 1, 'Processing': 1, 'helps': 1, 'computers': 1, 'understand': 1, 'human': 1, 'language': 1})\n",
            "After Removing Stop Words: ['Natural', 'Language', 'Processing', 'helps', 'computers', 'understand', 'human', 'language']\n",
            "POS Tags: [('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'VBG'), ('helps', 'NNS'), ('computers', 'NNS'), ('understand', 'NN'), ('human', 'NN'), ('language', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "text = \"Natural Language Processing helps computers understand human language.\"\n",
        "\n",
        "# Tokenize\n",
        "tokens = re.findall(r'\\w+', text)\n",
        "\n",
        "# Word frequency\n",
        "print(\"Word Frequency:\", Counter(tokens))\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = {'a', 'an', 'the', 'and', 'in', 'on', 'of', 'for', 'to', 'is', 'are', 'was', 'be', 'by'}\n",
        "filtered = [w for w in tokens if w.lower() not in stop_words]\n",
        "print(\"Filtered:\", filtered)\n",
        "\n",
        "# Simple POS tagging\n",
        "tags = [(w, 'VBG' if w.endswith('ing') else 'NN') for w in filtered]\n",
        "print(\"POS Tags:\", tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhDVbS3AqwaG",
        "outputId": "9cbe92c4-54c4-44ef-b3d5-256d7d5bb8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequency: Counter({'Natural': 1, 'Language': 1, 'Processing': 1, 'helps': 1, 'computers': 1, 'understand': 1, 'human': 1, 'language': 1})\n",
            "Filtered: ['Natural', 'Language', 'Processing', 'helps', 'computers', 'understand', 'human', 'language']\n",
            "POS Tags: [('Natural', 'NN'), ('Language', 'NN'), ('Processing', 'VBG'), ('helps', 'NN'), ('computers', 'NN'), ('understand', 'NN'), ('human', 'NN'), ('language', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioCwwNRgrMzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}